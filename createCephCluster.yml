
# Creating VMs

- hosts: operation_node_to_add
  gather_facts: false
  vars_files:
    vars_files/ceph-vars.yml
  tasks:
    - name: Create VMs
      proxmox_kvm:
        node: "{{ item.operation_node_short }}"
        api_user: "{{ item.api_user }}"
        api_password: "{{ item.api_pass }}"
        api_host: "{{ item.operation_node_short }}"
        clone: "{{ item.template_name }}"
        target: "{{ item.operation_node_short }}"
        vmid: "{{ item.template_id }}"
        newid: "{{ item.vm_id }}"
        name: "{{ item.vm_name }}"
        cores: "{{ item.cores_num }}"
        vcpus: "{{ item.vcpus_num }}"
        memory: "{{ item.memory_size }}"
        timeout: 300
      with_items:
        - "{{ ceph_admin_vars }}"
        - "{{ ceph_mon_vars }}"
        - "{{ ceph_osd_vars }}"
    - name: Set VMs
      proxmox_kvm:
        node: "{{ item.operation_node_short }}"
        api_user: "{{ item.api_user }}"
        api_password: "{{ item.api_pass }}"
        api_host: "{{ item.operation_node_short }}"
        name: "{{ item.vm_name }}"
        boot: "{{ item.boot_order }}"
        scsihw: "{{ item.scsi_hw }}"
        virtio:
          virtio0: "{{ item.virtio_disc }}"
        net:
          net0: "{{ item.net0_hw }}"
        cores: "{{ item.cores_num }}"
        vcpus: "{{ item.vcpus_num }}"
        memory: "{{ item.memory_size }}"
        searchdomains: "{{ item.searchdomain_cloud }}"
        nameservers: "{{ item.nameserver_cloud }}"
        ciuser: "{{ item.ceph_user }}"
        cipassword: "{{ item.ceph_pass }}"
        sshkeys: 'sshkeys_to_add'
        ipconfig:
          ipconfig0: "{{ item.network_cloud }}"
        update: yes
        timeout: 300
      with_items:
        - "{{ ceph_admin_vars }}"
        - "{{ ceph_mon_vars }}"
        - "{{ ceph_osd_vars }}"
    - name: Add osd disks
      proxmox_kvm:
        node: "{{ item.operation_node_short }}"
        api_user: "{{ item.api_user }}"
        api_password: "{{ item.api_pass }}"
        api_host: "{{ item.operation_node_short }}"
        name: "{{ item.vm_name }}"
        virtio:
          virtio2: 'LVM-1,64,format=raw'
      #shell: qm set "{{ item.vm_id }}" --"{{ item.osd_disk_type }}" "{{ item.osd_disk }}"
      with_items:
        - "{{ ceph_osd_vars }}"
    - name: Start VMs
      proxmox_kvm:
        node: "{{ item.operation_node_short }}"
        api_user: "{{ item.api_user }}"
        api_password: "{{ item.api_pass }}"
        api_host: "{{ item.operation_node_short }}"
        name: "{{ item.vm_name }}"
        state: started
        update: yes
        timeout: 120
      with_items:
        - "{{ ceph_admin_vars }}"
        - "{{ ceph_mon_vars }}"
        - "{{ ceph_osd_vars }}"
    - name: Waiting for full VMs start
      wait_for:
        host: "{{ item.ip_cloud }}"
        port: 22
        delay: 120
      with_items:
        - "{{ ceph_admin_vars }}"
        - "{{ ceph_mon_vars }}"
        - "{{ ceph_osd_vars }}"


# Setting enviorment      
       
- hosts: cephcluster
  gather_facts: false
  vars_files:
    vars_files/ceph-vars.yml
  tasks:
  - name: Set hostname
    replace:
      path: /etc/hostname
      regexp: '.{{ item.searchdomain_cloud }}'
      replace: ''
    with_items:
      - "{{ ceph_admin_vars }}"
      - "{{ ceph_mon_vars }}"
      - "{{ ceph_osd_vars }}"
  - name: Set localhost
    lineinfile:
      path: /etc/cloud/templates/hosts.redhat.tmpl 
      line: 127.0.0.1 localhost
  - name: Set hosts
    lineinfile:
      path: /etc/cloud/templates/hosts.redhat.tmpl 
      line: '{{ item.ip_cloud }} {{ item.vm_name }}.{{ item.ceph_domain }} {{ item.vm_name }}'
    with_items: 
      - "{{ ceph_admin_vars }}"
      - "{{ ceph_mon_vars }}"
      - "{{ ceph_osd_vars }}" 
  - reboot: 
  - name: Set fingerprint    
    shell: |
           ssh-keyscan 127.0.0.1 >> /{{ item.ceph_user }}/.ssh/known_hosts
           ssh-keyscan localhost >> /{{ item.ceph_user }}/.ssh/known_hosts
           ssh-keyscan "{{ item.ip_cloud }}" >> /{{ item.ceph_user }}/.ssh/known_hosts
    with_items: 
      - "{{ ceph_admin_vars }}"
      - "{{ ceph_mon_vars }}"
      - "{{ ceph_osd_vars }}"
  - name: Set ssh config
    shell: echo -e 'Host {{ item.vm_name }}\n    Hostname {{ item.ip_cloud }}\n    User {{ item.ceph_user }}' >> /{{ item.ceph_user }}/.ssh/config
    with_items: 
      - "{{ ceph_admin_vars }}"
      - "{{ ceph_mon_vars }}"
      - "{{ ceph_osd_vars }}"
  - name: Send id_rsa
    copy:
      src: id_rsa
      dest: /{{ item.ceph_user }}/.ssh/id_rsa
      owner: "{{ item.ceph_user }}"
      group: "{{ item.ceph_user }}"
      mode: '400'
    with_items: 
      - "{{ ceph_admin_vars }}"
  - name: Upgrade packages
    dnf: 
      name: "*"
      state: latest
  - name: Set keyboard
    shell: localectl set-keymap "{{ item.keyboard_layout }}"
    with_items: 
      - "{{ other_vars }}"
  - name: Enable ssh password login
    replace:
      path: /etc/ssh/sshd_config
      regexp: 'PasswordAuthentication no'
      replace: 'PasswordAuthentication yes'
  - name: Restart sshd
    systemd:
      state: restarted
      name: sshd
  - name: Install components
    dnf:
      name: 
        - qemu-guest-agent
        - python3
        - python3-pip
        - chrony
        - lvm2
        - crun
        - runc
      state: latest
  - name: Set qemu-guest-agent
    systemd:
      name: qemu-guest-agent
      state: started
      enabled: yes
  - name: dnf -y install podman
    dnf:
      name: podman
      state: present          
  - name: Set time-zone
    timezone:
      name: "{{ item.time_zone }}"
    with_items:
      - "{{ other_vars }}"
  - name: Chrony enable
    systemd:
      name: chronyd
      enabled: yes
  - name: Remove /etc/chrony.conf
    file:
      path: /etc/chrony.conf
      state: absent
  - name: Create /etc/chrony.conf
    file:
      path: /etc/chrony.conf
      state: touch
  - name: Get cephadm
    uri: 
      url: "{{ item.ceph_url }}"
      dest: /{{ item.ceph_user }}
    with_items: 
      - "{{ ceph_admin_vars }}"
  - name: Change cephadm permisions
    file:  
      path: /{{ item.ceph_user }}/cephadm
      mode: '0755'
    with_items: 
      - "{{ ceph_admin_vars }}"
  - name: execute cephadm add-repo --release octopus
    shell: ./cephadm add-repo --release octopus
  - name: execute cephadm install
    shell: ./cephadm install
  - name: execute cephadm install ceph-common ceph-osd
    shell: cephadm install ceph-common ceph-osd
  - name: mkdir -p /etc/ceph
    file:
      path: /etc/ceph
      state: directory
      owner: "{{ item.ceph_user }}"
      group: "{{ item.ceph_user }}"
      mode: 0775
    with_items: 
      - "{{ ceph_admin_vars }}"
  - name: Upgrade packages
    dnf: 
      name: "*"
      state: latest 

# Set chronyd server

- hosts: cephadmin
  gather_facts: false
  vars_files:
    vars_files/ceph-vars.yml
  tasks:
  - name: Set chronyd server config
    shell: echo -e "{{ item.chrony_server_set }}" >> /etc/chrony.conf
    with_items: 
      - "{{ other_vars }}"
  - name: Set chronyd
    shell: timedatectl set-ntp true
  - name: Restart chronyd
    systemd:
      state: restarted
      name: chronyd
      
- hosts: cephmons
  gather_facts: false
  vars_files:
    vars_files/ceph-vars.yml
  tasks:
  - name: Set chronyd server config
    shell: echo -e "{{ item.chrony_server_set }}" >> /etc/chrony.conf
    with_items:
      - "{{ other_vars }}"
  - name: Set chronyd
    shell: timedatectl set-ntp true
  - name: Restart chronyd
    systemd:
      state: restarted
      name: chronyd

# Set chronyd clients

- hosts: cephosds
  gather_facts: false
  vars_files:
    vars_files/ceph-vars.yml
  tasks:
  - name: Set chronyd client config
    lineinfile:
      path: /etc/chrony.conf
      line: 'server {{ item.ip_cloud }}'
    with_items: 
      - "{{ ceph_admin_vars }}"
      - "{{ ceph_mon_vars }}"
  - name: Set chronyd
    shell: timedatectl set-ntp true
  - name: Restart chronyd
    systemd:
      state: restarted
      name: chronyd
      
# Set cluster - ultimate        

- hosts: cephadmin
  gather_facts: false
  vars_files:
    vars_files/ceph-vars.yml
  tasks:
  - name: Set bootstrap
    shell: cephadm bootstrap --mon-ip "{{ item.ip_cloud }}" --initial-dashboard-password 'admin'
    with_items: 
      - "{{ ceph_admin_vars }}"
  - name: Send ceph_key
    shell: ssh-copy-id -f -i /etc/ceph/ceph.pub "{{ item.ceph_user }}"@"{{ item.vm_name }}"
    with_items: 
      - "{{ ceph_mon_vars }}"
      - "{{ ceph_osd_vars }}"
  - name: Add hosts to cephadmin
    shell: ceph orch host add "{{ item.vm_name }}" "{{ item.ip_cloud }}" --labels _admin
    with_items: 
      - "{{ ceph_mon_vars }}"
      - "{{ ceph_osd_vars }}"
  - name: Set unmanaged mon
    shell: ceph orch apply mon --unmanaged
  - name: Add mons
    shell: ceph orch daemon add mon "{{ item.vm_name }}":"{{ item.ip_cloud }}"
    with_items: 
      - "{{ ceph_mon_vars }}"
  - name: Add osds
    shell: ceph orch daemon add osd "{{ item.vm_name }}":/dev/sdb
    with_items: 
      - "{{ ceph_osd_vars }}"
  - name: Set Telemetry
    shell: ceph telemetry on --license sharing-1-0

# Show message about ceph-admin access

- hosts: operation_node_to_add
  gather_facts: false
  tasks:
    - shell: |
             echo "Ceph cluster is ready, to log into it. Type in browser: https://ceph_admin_ip_to_add:8443"
             echo "Default user and pass is: admin"
      register: result
    - debug:
        var: result.stdout_lines
